# LLM Privacy and Security Testing Framework: Context Primer

## Introduction

This framework provides a robust solution for automated security testing of Large Language Model (LLM) based chatbot systems. It simulates adversarial attacks (red-teaming) to identify potential vulnerabilities related to privacy, data security, prompt injection, and other misuse scenarios. The primary goal is to assess and enhance the resilience of chatbots against such threats.

## Core Components

The framework is architected around several key JavaScript modules and configuration files:

1.  **`SecurityTestManager.js` (Orchestrator)**:
    *   Manages the overall execution of security tests.
    *   Coordinates the running of multiple attack modes.
    *   Aggregates results from different attack runs.
    *   Initiates the analysis of attack transcripts.
    *   Can generate summary reports (including HTML if configured).

2.  **`attackerAgent.js` (Attack Executor)**:
    *   Responsible for executing individual attack strategies against the target chatbot.
    *   Loads attack configurations from JSON files.
    *   Leverages an LLM to dynamically generate domain-specific and context-aware attack prompts.
    *   Manages multi-turn conversations with the chatbot, adapting its approach based on responses.
    *   Handles LLM refusals with a retry and escalation strategy.
    *   Records detailed transcripts of each attack interaction.
    *   Supports parallel execution of different attack modes via its `runMultiple` method.

3.  **`attackTranscriptAnalyzer.js` (Results Analyzer)**:
    *   Analyzes the transcripts generated by the `AttackerAgent`.
    *   Utilizes an LLM for sophisticated, context-aware violation detection (this is non-optional if an LLM manager is provided).
    *   Identifies successful attacks, security violations, and extracts violating text segments.
    *   Calculates metrics like success rates, turns taken, and indicator frequencies.
    *   Generates a structured JSON analysis report for each attack mode.
    *   Aims to provide definitive judgments on whether a violation occurred, rather than leaving findings ambiguous.

4.  **Attack Mode Configurations (`attackModes/*.json`)**:
    *   These JSON files define specific adversarial strategies. Each file typically includes:
        *   `attackMode`: A unique name for the attack.
        *   `description`: Purpose of the attack.
        *   `instructions`: Guidelines for the LLM generating attack prompts.
        *   `strategy`, `persona`: Defines the attack's nature.
        *   `maxTurns`: Maximum conversation length.
        *   `trainingExamples`: Examples to guide the LLM.
        *   `successIndicators`, `failureIndicators`: Keywords/phrases to help identify outcomes.
        *   `analysisInstructions`: Specifics for the `AttackTranscriptAnalyzer` (e.g., `focus`, `suspectedLeakPatterns`).

## Workflow Overview

1.  **Initialization**: The `SecurityTestManager` is set up with parameters, including the target chatbot driver and an LLM manager.
2.  **Attack Execution**:
    *   The `SecurityTestManager` invokes `attackerAgent.runMultiple()`.
    *   The `AttackerAgent` loads configurations for various attack modes. For each mode, it (often in parallel with other modes):
        *   Generates an initial attack prompt using the LLM.
        *   Engages in a multi-turn conversation with the target chatbot.
        *   Generates follow-up prompts based on the conversation history and attack strategy.
        *   Records the full interaction in a transcript.
3.  **Results Analysis**:
    *   The `SecurityTestManager` receives the transcripts from the `AttackerAgent`.
    *   For each transcript, it uses the `AttackTranscriptAnalyzer` (often in parallel for different transcripts) to:
        *   Perform an in-depth, LLM-driven analysis of each conversation turn.
        *   Identify violations, reasoning, and confidence scores.
        *   Generate a detailed analysis report.
4.  **Aggregation & Reporting**:
    *   The `SecurityTestManager` aggregates metrics from all individual analysis reports.
    *   It produces a summary JSON file and can trigger the generation of HTML reports if configured.

## Key Features

*   **LLM-Driven Attacks**: Dynamically generated, context-aware adversarial prompts.
*   **LLM-Driven Analysis**: Sophisticated, contextual violation detection.
*   **Configurable Attack Strategies**: Easily define and add new attack modes via JSON.
*   **Parallel Execution**: Capable of running multiple attack modes and analyses in parallel for efficiency.
*   **Multi-Turn Conversations**: Simulates complex, adaptive attack scenarios.
*   **Detailed Reporting**: Generates structured JSON reports for individual attacks and an overall summary.

## Outputs

*   **Individual Attack Transcripts**: Raw logs of conversations for each attack mode (typically saved to files).
*   **Individual Analysis Reports**: JSON files detailing the findings for each attack mode.
*   **Security Test Summary**: An aggregated JSON file summarizing metrics across all attacks.
*   **HTML Reports (Optional)**: Visual reports for individual attacks and a summary if the generation logic is provided.

This framework is designed to be a comprehensive tool for proactively identifying and mitigating security risks in LLM-powered conversational AI systems.