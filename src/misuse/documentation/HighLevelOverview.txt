# High Level Overview

**By Brandon Young**

---

## Overview

The Misuse feature is designed to ensure that a specified large language model (LLM) remains focused on its defined domain(s) of expertise. It aims not only to identify but also to highlight instances where the LLM deviates from its designated domain. This is accomplished through the use of adversarial and evaluative LLMs, which work together to rigorously test and analyze the LLM's responses, ensuring they align with the intended domain-specific content.

---

## Use Case

Imagine a healthcare organization has developed an AI-powered chatbot to assist users with general medical inquiries. This chatbot, however, must strictly adhere to healthcare-related topics and avoid certain sensitive subjects, such as specific treatments or patient information. Furthermore, the organization wants to ensure the chatbot does not veer off-topic into areas like politics or finance, which are irrelevant to its purpose and could lead to inappropriate or confusing responses.

---

## How to Use Misuse?

1. **Tell the Misuse Feature about Your Chatbot**  
   Configure the Misuse feature with essential details about your LLM-powered chatbot, including API access information and any specific rules it must follow.

2. **Define the Chatbotʼs Domain and Boundaries**  
   Specify the chatbot's domain (e.g., "Healthcare") and configure boundaries. This includes defining distraction topics (like "Politics" or "Finance") and identifying banned topics within the domain (such as "specific treatments" or "patient information").

3. **Start the Testing Process**  
   Initiate the Misuse feature, which uses the Adversarial Bot to engage the chatbot with off-topic prompts, testing its adherence to the specified domain.

4. **Analyze the Results**  
   Review the comprehensive report generated by the Evaluator Bot. The report highlights any detected deviations from the domain, providing insights into how the chatbot performed and where adjustments might be necessary.

---

## Objectives

### Main Objective

To automate the process of ensuring that an LLM chatbot responds exclusively to domain-specific queries and avoids discussing unrelated or sensitive topics.

### Specific Goals

- Identify instances of off-topic responses and deviations from the specified domain.
- Justify off-topic identification by providing clear rationale for detected deviations.
- Leverage AI to accomplish these objectives effectively.
- Achieve objectives without access to training data, enabling a black-box testing approach.

---

## Key Features

- **Minimal User Input**: Employs self-discovery techniques to reduce the need for user intervention, streamlining setup and operation.
- **Customizable Settings**: Enables easy adjustments to settings for each LLM, allowing configurations to be tailored to specific testing requirements.
- **Automated Reporting**: Provides summaries of findings and insights on detected misuse, helping users quickly assess domain adherence issues.
- **Flexible Configuration**: Supports detailed customization for distraction topics, banned topics, and acceptable off-domain topics.
- **Automatic Misuse Topic Generation**: Automatically generates suggested off-topic subjects based on the specified domain.
- **Insightful Deviation Analysis**: Provides a detailed breakdown of the conversational steps that led to any domain deviation.
- **Advanced Topic Exclusion and Inclusion**: Specify topics within the domain to avoid (banned topics) and acceptable topics outside the domain (allowed off-domain topics).
- **Prioritisation of Banned Topics**: Ensures high-risk forbidden subjects are thoroughly tested during misuse evaluation.

---

## Components

The system conceptually consists of three distinct LLMs working together:

1. **Target Bot (Target LLM)**  
   Represents the clientʼs chatbot, designed to deliver information exclusively within a specified domain.

2. **Testing LLM (Adversarial Bot)**  
   Interacts directly with the Target Bot to steer the conversation off-topic using creative questions, statements, or anecdotes.

3. **Analysis LLM (Evaluator Bot)**  
   Analyzes the conversation and detects off-topic content, providing a report on deviations.

---

## User Interface

- **Data Collection**: Interface for entering Target Bot details, including domains, banned topics, allowed topics, and API info.
- **Analysis Review**: Presents results clearly, highlighting any domain deviations.

---
